{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4a9fa148-ffc0-4329-947f-d25a784b4866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import dlib\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "\n",
    "def extrai_descritor(face,imagem_np,descritores_face):\n",
    "\n",
    "    \n",
    "    l,t,r,b = face.left(),face.top(),face.right(),face.bottom()\n",
    "    pontos = detector_pontos(imagem_np,face)\n",
    "\n",
    "    for ponto in pontos.parts():\n",
    "        cv2.circle(imagem_np,(ponto.x,ponto.y),2,(0,255,0),1)\n",
    "\n",
    "    descritor_face = extrator_descritor_facial.compute_face_descriptor(imagem_np,pontos)\n",
    "    descritor_face = [f for f in descritor_face]\n",
    "    descritor_face = np.asarray(descritor_face,dtype=np.float64)\n",
    "    descritor_face = descritor_face[np.newaxis,:]\n",
    "\n",
    "    if descritores_face is None:\n",
    "        descritores_face = descritor_face\n",
    "        \n",
    "    else:\n",
    "        descritores_face = np.concatenate((descritores_face,descritor_face),axis=0)\n",
    "        \n",
    "\n",
    "    return imagem_np, descritores_face\n",
    "\n",
    "\n",
    "def carrega_treinamento(path_dataset):\n",
    "\n",
    "    index = {}\n",
    "    idx = 0\n",
    "    descritores_faces = None\n",
    "\n",
    "    paths = [os.path.join(path_dataset,f) for f in os.listdir(path_dataset)]\n",
    "\n",
    "    for path in paths:\n",
    "        \n",
    "        imagem = cv2.imread(path)                \n",
    "        \n",
    "        for face in deteccoes_faces:\n",
    "                     \n",
    "            imagem_np, descritores_faces = extrai_descritor(face,imagem,descritores_faces) \n",
    "            index[idx] = path\n",
    "            idx+=1\n",
    "\n",
    "    return descritores_faces, index\n",
    "\n",
    "\n",
    "\n",
    "def previsoes_dlib(path_dataset,descritores_faces,index,threshold = 0.5):\n",
    "\n",
    "    previsoes = []\n",
    "    saidas_esperadas = []\n",
    "\n",
    "    paths = [os.path.join(path_dataset,f) for f in os.listdir(path_dataset)]\n",
    "\n",
    "    for path in paths:\n",
    "        \n",
    "        imagem = cv2.imread(path) \n",
    "        (h,w) = imagem.shape[:2]\n",
    "\n",
    "        deteccoes_faces = detector_face(imagem,1)\n",
    "\n",
    "        for face in deteccoes_faces:\n",
    "            \n",
    "            pontos = detector_pontos(imagem,face)\n",
    "            descritor_face = extrator_descritor_facial.compute_face_descriptor(imagem,pontos)\n",
    "            descritor_face = [f for f in descritor_face]\n",
    "            descritor_face = np.asarray(descritor_face,dtype=np.float64)\n",
    "            descritor_face = descritor_face[np.newaxis,:]\n",
    "\n",
    "            distancias = np.linalg.norm(descritor_face - descritores_faces,axis=1)\n",
    "\n",
    "            min_index = np.argmin(distancias)\n",
    "\n",
    "            distancia_minima = distancias[min_index]\n",
    "\n",
    "            if distancia_minima <= threshold:\n",
    "                nome_previsao = \n",
    "            else:\n",
    "                nome_previsao = -1\n",
    "\n",
    "            nome_real = \n",
    "\n",
    "            previsoes.append(nome_previsao)\n",
    "            saidas_esperadas.append(nome_real)\n",
    "\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da53d452-5596-4712-b375-62af1178ae8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cc732b-cce5-44e0-989b-9a143b787f18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "924aa835-68f8-4a71-b087-5c5f57b96454",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_face = dlib.get_frontal_face_detector()\n",
    "detector_pontos = dlib.shape_predictor(\"Materiais\\\\weights\\\\weights\\\\shape_predictor_68_face_landmarks.dat\")\n",
    "extrator_descritor_facial = dlib.face_recognition_model_v1('Materiais\\\\weights\\\\weights\\\\dlib_face_recognition_resnet_model_v1.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4571d6e-b945-4218-a562-3783692bd013",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf420635-7f2d-4109-8b2f-55f76e6a697a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6edd2272-2d1e-4234-a0ce-2cd3b8b15854",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem = cv2.imread('Materiais\\\\images\\\\images\\\\people2.jpg')\n",
    "\n",
    "deteccoes_faces = detector_face(imagem,1)\n",
    "\n",
    "for face in deteccoes_faces:\n",
    "\n",
    "    pontos = detector_pontos(imagem,face)\n",
    "\n",
    "    for ponto in pontos.parts():\n",
    "        cv2.circle(imagem,(ponto.x,ponto.y),2,(0,255,0),1)\n",
    "\n",
    "    l, t, r, b = face.left(), face.top(), face.right(), face.bottom()\n",
    "\n",
    "    cv2.rectangle(imagem,(l,t),(r,b),(0,255,255),2)\n",
    "\n",
    "cv2.imshow(\"Rostos\",imagem)\n",
    "\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d990898-93dd-424c-baff-dab775de3663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9be70607-fcef-4c97-9b30-2443d0cf38eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_teste = \"Materiais\\\\datasets\\\\datasets\\\\FaceDataset\\\\test\\\\1-11.jpg\"\n",
    "imagem = cv2.imread(imagem_teste)\n",
    "\n",
    "imagem_cinza = cv2.cvtColor(imagem,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "deteccoes_faces = detector_face(imagem_cinza,1)\n",
    "\n",
    "for face in deteccoes_faces:\n",
    "\n",
    "    l,t,r,b = face.left(),face.top(),face.right(),face.bottom()\n",
    "\n",
    "    pontos = detector_pontos(imagem_cinza,face)\n",
    "\n",
    "    for ponto in pontos.parts():\n",
    "        cv2.circle(imagem,(ponto.x,ponto.y),2,(0,255,0),1)\n",
    "\n",
    "    \n",
    "    cv2.rectangle(imagem,(l,t),(r,b),(0,0,255),2)\n",
    "\n",
    "    descritor_face = extrator_descritor_facial.compute_face_descriptor(imagem,pontos)\n",
    "\n",
    "    descritor_face = [f for f in descritor_face]\n",
    "\n",
    "    descritor_face = np.asarray(descritor_face,np.float64)\n",
    "\n",
    "    descritor_face = descritor_face[np.newaxis,:]\n",
    "\n",
    "    \n",
    "\n",
    "cv2.imshow(\"Teste\",imagem)\n",
    "\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef01d1b-4b1f-42da-b57c-f982adcea58c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "30f37a0d-418d-4428-b80d-96cce9af9f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "descritores_face, index = carrega_treinamento('Materiais\\datasets\\\\datasets\\\\FaceDataset\\\\train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53194258-a506-4953-95d1-9c8c3c8ef8f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be504c6c-c8fc-4c7a-bd71-4af9dd553483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "da8e3c38-3b93-44ff-b675-efd456364d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Salva o modelo'''\n",
    "np.save('descritores_faces.npy',descritores_face)\n",
    "\n",
    "with open('index_faces.pickle','wb') as f:\n",
    "    pickle.dump(index,f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acacb536-9528-4708-9c9f-20b1f35cd578",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d9455404-88df-4c3e-a2af-722259e758a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Carrega o modelo'''\n",
    "descritores_faces = np.load('descritores_faces.npy')\n",
    "index = np.load('index_faces.pickle',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc5d5e5-7810-4608-9f68-e28a6783b951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "90604446-8d7f-409e-85ed-cc78e8f2ade3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(191, 191)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(descritores_faces),len(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f0489f26-d84a-45ed-b651-974ddbd1122e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5923690555348466"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(descritores_faces[122] - descritores_faces[123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c31bd68-a9ca-4be6-b139-3445cdcf7b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178b5088-b455-4618-8731-0fe50899ced1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fa3fac-ab0f-4cf6-a535-ba618acf986f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60849374-2665-4231-acdc-ab9a3b16d64f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf32e95-964c-4220-9424-0faa76243666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3384e076-9813-46a5-90fb-e063464581c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e476b98-08eb-4d03-8957-8b6aab986a36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5344c0-ed37-40a9-87a6-82d7dc00ba20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a20a443-73e3-4867-b170-816a93335f3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bbf4bd-5504-42a3-8f50-d0a1ab92afac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ff2bcb-e685-48d3-bfe2-176409d0e1cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb46aec-e500-4bee-aba2-c50bb01f0099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd43c10a-6721-4d99-97d6-0f655a34e535",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1523f27d-1726-413e-a452-62d2fadbaea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec285be-9fef-43e6-8074-4e4fdf727a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
